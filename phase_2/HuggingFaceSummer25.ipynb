{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace Exploration:\n",
        "\n",
        "\n",
        "1.   Get to know about Models, Datasets, and Spaces\n",
        "2.   Search for the bert-base-uncased model and open it\n",
        "3.   See the model card, model_size, framework, task, etc. of the model\n",
        "4.   Use the HuggingFace platform to test the model online\n",
        "\n"
      ],
      "metadata": {
        "id": "jIXljYP7bvcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Importing Required Packages\n",
        "\n"
      ],
      "metadata": {
        "id": "V5aO7GAJodY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "kp3Verrpoovo"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification\n"
      ],
      "metadata": {
        "id": "JVnUdpRU-jnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textclassifier = pipeline(task=\"text-classification\")\n",
        "print(textclassifier(\"The movie was awesome!\"))\n",
        "\n",
        "# Challenge: Confuse the model! Find an input that makes the model produce the score (confidence) below 0.6"
      ],
      "metadata": {
        "id": "Yu6LmrxH-j-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textclassifier.tokenizer"
      ],
      "metadata": {
        "id": "jhaMyBYxuEyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textclassifier.model"
      ],
      "metadata": {
        "id": "Wbj4EqNc4oNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token Classification"
      ],
      "metadata": {
        "id": "IoyCeqHS3qMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(task=\"token-classification\")\n",
        "print(classifier(\"Ronaldo\"))\n",
        "\n",
        "# Challenge: Searching or Trying? Find more entity types (e.g., \"I-PER\", \"I-LOC\", etc.)"
      ],
      "metadata": {
        "id": "FnSR3o-Z3uiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill Mask"
      ],
      "metadata": {
        "id": "GL4XK7qM4T__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"fill-mask\")\n",
        "print(classifier(\"Paris is the <mask> of France.\"))\n",
        "\n",
        "# Challenge: Undercover: try to increase masked words to see the model behaviour"
      ],
      "metadata": {
        "id": "J4O6s4BO_zR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table Question Answering"
      ],
      "metadata": {
        "id": "ckLX3ZQK3vYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqa = pipeline(task=\"table-question-answering\")\n",
        "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
        "table = pd.DataFrame.from_dict(data)\n",
        "question = \"which actor has played in 53 movies?\"\n",
        "print(tqa(table=table, query=question)['cells'][0])\n",
        "\n",
        "# Challenge: Predictable model! How many different answers we might see?"
      ],
      "metadata": {
        "id": "NR66JwBn_YN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering"
      ],
      "metadata": {
        "id": "JCVdqHEx36DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(task=\"question-answering\")\n",
        "context = \"Brad Pitt has 87, Leonardo Di Caprio has 53, and George Clooney has 69 movies.\"\n",
        "question = \"how many movies has Leonardo Di Caprio played in?\"\n",
        "print(qa(question = question, context = context))\n",
        "\n",
        "# Challenge: Let's take a deeper look! See the architecture of the model by calling .model.config"
      ],
      "metadata": {
        "id": "vFimLtABAmZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Classification"
      ],
      "metadata": {
        "id": "tCMDdwmC3-cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zsc = pipeline(task=\"zero-shot-classification\")\n",
        "print(zsc(\"Inception is the best movie ever\",\n",
        "    candidate_labels=[\"CINEMA\", \"MUSIC\", \"ART\"],\n",
        "))\n",
        "\n",
        "# Challenge: Unique English words! What is the vocab_size of the Tokenizer used by zsc?"
      ],
      "metadata": {
        "id": "SmgMZOwMCpo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "XJSzVq3D3-5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fr_en_translator = pipeline(task=\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "fr_en_translator(\"quelle distance se trouve la ville la plus proche?\")\n",
        "\n",
        "# Challenge: Multilinguality! How many languages does this task support?"
      ],
      "metadata": {
        "id": "PN-skZoTQvoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization"
      ],
      "metadata": {
        "id": "qKpidDL63_Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "txt = \"Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018, in an area of more than 105 square kilometres (41 square miles). The City of Paris is the centre and seat of government of the region and province of ÃŽle-de-France, or Paris Region, which has an estimated population of 12,174,880, or about 18 percent of the population of France as of 2017.\"\n",
        "print(f\"the original text has {len(txt.split())} tokens\")\n",
        "output = summarizer(txt, max_length=50)\n",
        "print(f\"Summary: {output}\")\n",
        "print(f\"the summarized text has {len(output[0]['summary_text'].split())} tokens\")\n",
        "# Challenge: SHORTEEERRR! Force the model to keep the summary under 10 words."
      ],
      "metadata": {
        "id": "c2OwVJR4h1mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation"
      ],
      "metadata": {
        "id": "_SX5Dv4S4Mku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(task=\"text-generation\")\n",
        "generator(\"Hello, I'm a student at\", num_return_sequences=2)\n",
        "\n",
        "# Challenge: Lullaby! Force the model to tell you a single long story."
      ],
      "metadata": {
        "id": "jks7ZwRwrcYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "kU4XF3By4KTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vm1Gt43U2ymg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = pipeline(\"feature-extraction\", framework=\"pt\")\n",
        "text = \"Transformers is an awesome library!\"\n",
        "a = feature_extractor(text,return_tensors = \"pt\")[0].numpy().mean(axis=0)\n",
        "\n",
        "# Challenge: Does fraework matter? pt stands for PyTorch. Will we get the same output if we use TensorFlow?"
      ],
      "metadata": {
        "id": "yYaMZA32j6HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "id": "a1CcgaQz2-HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Similarity"
      ],
      "metadata": {
        "id": "FFQCQwf54Xz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "sentences = [\n",
        "    \"Competition day is next week\",\n",
        "    \"Mastering this will greatly help\",\n",
        "    \"Let's have a fun competition next week\"]\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "similarities = model.similarity(embeddings, embeddings)\n",
        "print(similarities)\n",
        "\n",
        "\n",
        "# Challenges:\n",
        "    # What was different for this task? Try pipeline('sentece-similarity')\n",
        "    # Try to add more sentences\n",
        "    # what is the vector size (embedding dimension)?\n",
        "    # Try words instead of sentences"
      ],
      "metadata": {
        "id": "Bobqp8TPBpof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "F2F-AsR31DTM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Soviq8rkXctd"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
        "model = AutoModel.from_pretrained('prajjwal1/bert-tiny')"
      ],
      "metadata": {
        "id": "hRcUSsQFihF5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\", model=\"prajjwal1/bert-tiny\")\n",
        "\n",
        "# Add a mask token to complete the sentence\n",
        "output = fill_mask(\"[MASK] is a game.\")\n",
        "for prediction in output:\n",
        "    print(f\"{prediction['sequence']} (score: {prediction['score']:.4f})\")"
      ],
      "metadata": {
        "id": "CAoPwRUji7zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ds = pd.read_csv('game.csv')"
      ],
      "metadata": {
        "id": "Wqc6aG6jofa8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, load_dataset\n",
        "dataset = Dataset.from_pandas(ds)"
      ],
      "metadata": {
        "id": "4U4vOYABpRCw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "\n",
        "def tokenize_function(txt):\n",
        "    return tokenizer(txt[\"description\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "lTIPGlkIpyjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "block_size = 1\n",
        "\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts in the batch for token-related columns\n",
        "    concatenated_examples = {k: list(itertools.chain.from_iterable(examples[k])) for k in examples.keys() if k in ['input_ids', 'token_type_ids', 'attention_mask']}\n",
        "    total_length = len(concatenated_examples[list(concatenated_examples.keys())[0]])\n",
        "    # Drop the small remainder of smaller than block_size\n",
        "    total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of max_len\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "\n",
        "lm_dataset = tokenized_dataset.map(\n",
        "    group_texts,\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        "    remove_columns=tokenized_dataset.column_names,  # CRITICAL to prevent shape mismatch\n",
        ")"
      ],
      "metadata": {
        "id": "aYT9Oxt7unIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-mlm2\",\n",
        "    per_device_train_batch_size=1,\n",
        "    num_train_epochs=2,\n",
        "    prediction_loss_only=True,\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=lm_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "qgxeLAQWqJHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model_path = \"./bert-mlm2/checkpoint-7000\" # Updated path to the checkpoint directory\n",
        "finetuned_model = AutoModelForMaskedLM.from_pretrained(finetuned_model_path)\n",
        "\n",
        "finetuned_fill_mask = pipeline(\"fill-mask\", model=finetuned_model, tokenizer=tokenizer)\n",
        "\n",
        "output_finetuned = finetuned_fill_mask(\"[MASK] is a game.\")\n",
        "print(\"\\nPredictions from fine-tuned model:\")\n",
        "for prediction in output_finetuned:\n",
        "    print(f\"{prediction['sequence']} (score: {prediction['score']:.4f})\")\n"
      ],
      "metadata": {
        "id": "Peetvtw-wsVm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}