{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Input:\n",
        "\n",
        "A list of sentences in English.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "##Translation Chain:\n",
        "\n",
        "For each sentence, translate it through four different languages (***Spanish***, ***French***, ***Arabic***, ***Chinese***), one after another, and **finally back into English**.\n",
        "\n",
        "\n",
        "*   The translation path must begin and end with English.\n",
        "*   The order of the four languages is up to you, but each must be used exactly once per sentence.\n",
        "---\n",
        "##Output\n",
        "*   Store the final, back-translated English sentences in a list named `output`.\n",
        "*   The `output` list must have the same length as the `sentences` list.\n",
        "*   Each element in `output` should correspond to the back-translated version of the sentence at the same index in the `sentences`."
      ],
      "metadata": {
        "id": "hez8wVCwdfvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG6iB31JZK3p"
      },
      "outputs": [],
      "source": [
        "sentences = [\"Considering the unpredictable nature of global events, maintaining a flexible and adaptable strategy is paramount for long-term success in any international endeavor.\",\n",
        "             \"Hello from the other side\",\n",
        "             \"It’s raining cats and dogs\",\n",
        "             \"She let the cat out of the bag\",\n",
        "             \"He kicked the bucket\",\n",
        "             \"Time flies\",\n",
        "             \"I feel blue\",\n",
        "             \"I saw her duck\",\n",
        "             \"The chicken is ready to eat\",\n",
        "             \"They’re painting the town red\",\n",
        "             \"He left his heart in San Francisco\",\n",
        "             \"Don’t judge a book by its cover\",\n",
        "             \"Barking up the wrong tree\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q9_GonWafayo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you have created your `output` list, use the provided code block to calculate the average cosine similarity score between your back-translated sentences and the original inputs.\n",
        "\n",
        "*   Run the given code block to obtain your score.\n",
        "*   Report your average similarity score as your competition result."
      ],
      "metadata": {
        "id": "eixx-XvgfdVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from torch.nn.functional import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Load a sentence embedding model\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode\n",
        "def get_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Mean pooling\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "sims = []\n",
        "for s,t in zip(sentences, output):\n",
        "  emb1 = get_embedding(s)\n",
        "  emb2 = get_embedding(t)\n",
        "  similarity = cosine_similarity(emb1, emb2).item()\n",
        "  sims.append(similarity)\n",
        "\n",
        "average_similarity = np.mean(sims)\n",
        "print(f\"Average Similarity: {average_similarity:.4f}\")"
      ],
      "metadata": {
        "id": "5ivGMHihf8K-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}