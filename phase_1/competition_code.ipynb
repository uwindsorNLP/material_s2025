{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This is going to be the easiest competition ever! You just need to run the code blocks step by step.\n",
        "\n",
        "**GitHub repo:**\n",
        "https://github.com/uwindsorNLP/material_s2025/tree/main"
      ],
      "metadata": {
        "id": "y3Rz4q5EYKQB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5aO7GAJodY-"
      },
      "source": [
        "# Step 0: Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kp3Verrpoovo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gensim\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Got an error?! Try to solve it :)"
      ],
      "metadata": {
        "id": "7synl7m7aYsc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLL8thlcnchC"
      },
      "source": [
        "# Step 1: Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eqyaIczBnZ8q"
      },
      "outputs": [],
      "source": [
        "news_df = pd.read_csv(\"reddit_worldnews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Another error?! Again?!! What you can do about it?\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "You need to have a **CSV** file in the Files section. First, find and download it from the GitHub repo, then upload it to the Files section. Note that the file in the repo is in .txt format; Inpect it to find the CSV file.\n"
      ],
      "metadata": {
        "id": "tfJndRZKXZo9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8wfuo4SpJ99"
      },
      "source": [
        "# Step 2: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JwWuWnrKMTBR"
      },
      "outputs": [],
      "source": [
        "def preprocess_df(df: pd.Series) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Preprocess the input DataFrame.\n",
        "\n",
        "    This function should perform text preprocessing task which may include:\n",
        "      - Converting text to lowercase\n",
        "      - Removing punctuations and whitespaces\n",
        "      - Removing stopwords\n",
        "      - Stemming or Lemmatizing\n",
        "      - (Other preprocessing steps as you wish)\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): A DataFrame containing at least a column\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with the preprocessed column.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement the preprocessing logic\n",
        "    # df = df.str.lower()  # Convert to lowercase\n",
        "    # You can extend this with additional preprocessing steps.\n",
        "\n",
        "    # Example (simple preprocessing):\n",
        "    df = df.apply(gensim.utils.simple_preprocess)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df = preprocess_df(news_df['title'])"
      ],
      "metadata": {
        "id": "eUmqrJYiZFwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkkIjQNJ1ZGa"
      },
      "source": [
        "# Step 3: Build the Model\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "**vector_size** = (int) - Dimensionality of the feature vectors.\n",
        "\n",
        "**alpha** = (float) - The initial learning rate\n",
        "\n",
        "**window** = (int) - The maximum distance between the current and predicted word within a sentence.\n",
        "\n",
        "**min_count** = (int) - Ignores all words with total frequency lower than this.\n",
        "\n",
        "**epochs** = (int) - Number of iterations over the whole dataset\n",
        "\n",
        "\n",
        "more info: https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial#Training-the-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISlY5L3_1fth"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "        window=******,\n",
        "        vector_size=******,\n",
        "        alpha=******,\n",
        "        min_count=******,\n",
        "        epochs=******\n",
        "        )\n",
        "\n",
        "model.build_vocab(processed_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "        window=3,\n",
        "        vector_size=128,\n",
        "        alpha=0.1,\n",
        "        min_count=2,\n",
        "        epochs=5\n",
        "        )\n",
        "\n",
        "model.build_vocab(processed_df)"
      ],
      "metadata": {
        "id": "75l74_TKZmAR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfI3vQLL-Ta9"
      },
      "source": [
        "# Step 4: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GncxfTx0_XlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb8c0bc-5e1b-48dc-d6e9-4d489da216ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30324191, 35114280)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.train(processed_df, total_examples=model.corpus_count, epochs=model.epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-CU13ay_eGA"
      },
      "source": [
        "# Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, download the file youâ€™re trying to read in the first line of code from the GitHub repo, and upload it to the Files section."
      ],
      "metadata": {
        "id": "Da6YcoOidQFW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "I5D50ylB_ebY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a30be75-5410-4764-d407-f8be24f7cd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___** FINAL RESULTS **___\n",
            "\n",
            "missed_pairs: 24\n",
            "spearmanr_score: 0.5252467217799474\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_csv(\"wordsim353crowd.csv\")\n",
        "df_test['Human (Mean)']/=df_test['Human (Mean)'].max()\n",
        "predictions = []\n",
        "gt_list = []\n",
        "missed_pairs = 0\n",
        "for row in df_test.iterrows():\n",
        "  try:\n",
        "    model_output = model.wv.similarity(w1=row[1]['Word 1'], w2=row[1]['Word 2'])\n",
        "    predictions.append(model_output)\n",
        "    gt_list.append(row[1]['Human (Mean)'])\n",
        "  except:\n",
        "    missed_pairs+=1\n",
        "spearmanr_score = stats.spearmanr(predictions, gt_list)\n",
        "print(\"___** FINAL RESULTS **___\\n\")\n",
        "print(f'missed_pairs: {missed_pairs}')\n",
        "print(f'spearmanr_score: {spearmanr_score.statistic}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report the results (missed pairs and spearman score) to see your ranking!"
      ],
      "metadata": {
        "id": "887LFLALb5OC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}